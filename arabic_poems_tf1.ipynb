{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "arabic poems tf1",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNjC+Bj4qFFFJyIxxegu9h9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ojuba-org/arabic-ml-data/blob/master/arabic_poems_tf1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7Nzhoae6oyN"
      },
      "source": [
        "Tensorflow documentation\n",
        "\n",
        "* [v2](https://www.tensorflow.org/tutorials/text/text_generation)\n",
        "* [v1](https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/text_generation.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bB-XTwj9io8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1516cad5-a21b-44ac-8998-4ec3aa6c4dcd"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOeUIdNu_AU-"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60OfCkAv-mMZ"
      },
      "source": [
        "import re\n",
        "import unicodedata"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApcMwBdi9sgg"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33-0GY_z7RIr"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bst7e-d8KIGS"
      },
      "source": [
        "tf.enable_eager_execution()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vCqr4qy7STc"
      },
      "source": [
        "#import tensorflow.compat.v1 as tf"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFID0M6u9xbf",
        "outputId": "25fb66d8-4b5b-4ec8-e1b2-6b9fb1753207"
      },
      "source": [
        "print(\"tf version = {} and py version = {}\".format(tf.__version__, sys.version))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf version = 1.15.2 and py version = 3.7.10 (default, Feb 20 2021, 21:17:23) \n",
            "[GCC 7.5.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XJ6ovEI-AED"
      },
      "source": [
        "assert sys.version_info.major == 3, 'please use python 3'\n",
        "assert tf.test.gpu_device_name()!='', 'no GPU, please enable GPU'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrUDr7WY_cuu"
      },
      "source": [
        "#from tensorflow.keras.layers.experimental import preprocessing\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnXXpLEm5cCp"
      },
      "source": [
        "! curl -sSLO https://github.com/ojuba-org/arabic-ml-data/archive/refs/heads/master.zip"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuBEml2pKA9U"
      },
      "source": [
        "! unzip -q master.zip \"arabic-ml-data-master/corpora/poems/*/*.txt\""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUnBxW1qKflI",
        "outputId": "f849bb30-57ab-4675-c4f8-45bbc40bd13e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! cat arabic-ml-data-master/corpora/poems/*/*.txt > poems.txt; wc -l poems.txt"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "273190 poems.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY9L48SU6T3M"
      },
      "source": [
        "fn = 'poems.txt'\n",
        "with open(fn, 'r') as f:\n",
        "  text = f.read()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y55q1sTg-k8y"
      },
      "source": [
        "en_re = re.compile('^[a-zA-Z].*$', re.M)\n",
        "dline_regex = re.compile('^\\d+$', re.M)\n",
        "spaces_regex = re.compile('[ \\t]+', re.M)\n",
        "dots_regex = re.compile('\\.{2,}', re.M)\n",
        "leading_digits_regex = re.compile('^ *[0-9]+', re.M)\n",
        "special_regex = re.compile('[-–_\"\\(\\)\\[\\]\\<\\>\\*\\+/\\\\:,،=«»“”|\\u2019\\u200d\\u200f\\u202c\\u202e\\u25a1\\ufd3e\\ufd3f]+', re.M)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMgA6G9SG2hG"
      },
      "source": [
        "def clean_txt(body):\n",
        "    body = unicodedata.normalize('NFKC', body)\n",
        "    body = body.replace('ـ', '').replace('?', '؟').replace(';', '؛').replace(',', '،').replace('\\\\', ' ')\n",
        "    body = special_regex.sub(' ', body)\n",
        "    body = leading_digits_regex.sub('', body)\n",
        "    body = dots_regex.sub('…', body).replace('.', ' ')\n",
        "    body = dline_regex.sub('', body)\n",
        "    body = spaces_regex.sub(' ', body)\n",
        "    return body.strip()\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLZ6SBE9-vNw"
      },
      "source": [
        "text = clean_txt(en_re.sub('', text))\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VBLGos-h6WEy",
        "outputId": "972dc389-a772-43f4-90b8-22f6b7f7c565"
      },
      "source": [
        "text[:100]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'الناس ثلاث امواتٍ\\n\\nفي اوطاني\\n\\nوالميت معناه قتيل\\n\\nقسم يقتله اصحاب الفيل\\n\\nوالثاني تقتله اسرائيل\\n\\nوالثا'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCZfzRDd78FF"
      },
      "source": [
        "vocab = sorted(set(text))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmPVr4zk8BCK",
        "outputId": "639c366a-ee9d-48de-83eb-14fc597b94c3"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0X3X_2X8CFC",
        "outputId": "03c2d0ed-5849-47f4-b839-e14fbee9da27"
      },
      "source": [
        "vocab"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " '؛',\n",
              " '؟',\n",
              " 'ء',\n",
              " 'آ',\n",
              " 'أ',\n",
              " 'ؤ',\n",
              " 'إ',\n",
              " 'ئ',\n",
              " 'ا',\n",
              " 'ب',\n",
              " 'ة',\n",
              " 'ت',\n",
              " 'ث',\n",
              " 'ج',\n",
              " 'ح',\n",
              " 'خ',\n",
              " 'د',\n",
              " 'ذ',\n",
              " 'ر',\n",
              " 'ز',\n",
              " 'س',\n",
              " 'ش',\n",
              " 'ص',\n",
              " 'ض',\n",
              " 'ط',\n",
              " 'ظ',\n",
              " 'ع',\n",
              " 'غ',\n",
              " 'ف',\n",
              " 'ق',\n",
              " 'ك',\n",
              " 'ل',\n",
              " 'م',\n",
              " 'ن',\n",
              " 'ه',\n",
              " 'و',\n",
              " 'ى',\n",
              " 'ي',\n",
              " 'ً',\n",
              " 'ٌ',\n",
              " 'ٍ',\n",
              " 'َ',\n",
              " 'ُ',\n",
              " 'ِ',\n",
              " 'ّ',\n",
              " 'ْ',\n",
              " 'ٱ',\n",
              " 'پ',\n",
              " 'چ',\n",
              " 'ڤ',\n",
              " '…']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeUg0BHkJtgF"
      },
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdHso5vC8FpA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a45c34-5dc4-48eb-fc50-2597a96e351d"
      },
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//seq_length\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "  print(idx2char[i.numpy()])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ا\n",
            "ل\n",
            "ن\n",
            "ا\n",
            "س\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYE88T4nKs-C",
        "outputId": "c8db6aee-cc2b-408d-8118-f0379c637676"
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'الناس ثلاث امواتٍ\\n\\nفي اوطاني\\n\\nوالميت معناه قتيل\\n\\nقسم يقتله اصحاب الفيل\\n\\nوالثاني تقتله اسرائيل\\n\\nوالثال'\n",
            "'ث تقتله عربائيل\\n\\nوعربائيل بلادي\\n\\nتمتد من الكعبه حتى النيل\\n\\nوالله اشتقنا\\n\\nوالله اشتقنا\\n\\nللموت بلا تنكي'\n",
            "'ل\\n\\nوالله اشتقنا\\n\\nثم اشتقنا واشتقنا\\n\\nانقذنا يا عزرائيلحالةُ البَحْرِ زَبَدْ \\n\\nحالةُ البَرِّ نَكَدْ \\n\\nح'\n",
            "'الةُ الجَوِّ رَمَدْ \\n\\nحالةُ الحالِ احتلالٌ\\n\\nحالةُ الحَلِّ عُقَدْ\\n\\nطُولُها ألفُ أبَدْ \\n\\nحالةُ العِزَّة'\n",
            "'ِ جَزْرٌ\\n\\nحالةُ الذُُلَّةِ مَدْ \\n\\nوَفَياتُ اليَومِ \\n\\nلا قَلَّ ولا زادَ العَدَدْ\\n\\nنَفْسُ مَن كانوا مسا'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4ghvB6tJA__"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWzuAXvJJuos",
        "outputId": "17675c6c-b776-4ea7-bc49-7721a4ed0b9f"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function split_input_target at 0x7f43f77dce18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <function split_input_target at 0x7f43f77dce18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFpFS8FhKCER",
        "outputId": "be101235-d55f-45e2-aecf-470b05c3e227"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function split_input_target at 0x7f43f77dcd90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <function split_input_target at 0x7f43f77dcd90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7V2W33qKxL4",
        "outputId": "257f64cb-94e3-451e-c811-03c79b9180d0"
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  'الناس ثلاث امواتٍ\\n\\nفي اوطاني\\n\\nوالميت معناه قتيل\\n\\nقسم يقتله اصحاب الفيل\\n\\nوالثاني تقتله اسرائيل\\n\\nوالثا'\n",
            "Target data: 'لناس ثلاث امواتٍ\\n\\nفي اوطاني\\n\\nوالميت معناه قتيل\\n\\nقسم يقتله اصحاب الفيل\\n\\nوالثاني تقتله اسرائيل\\n\\nوالثال'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGqrfcCqK0EI",
        "outputId": "07849e9e-97ad-4878-bbcd-4c475372602f"
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "    print(\"Step {:4d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step    0\n",
            "  input: 21 ('ا')\n",
            "  expected output: 44 ('ل')\n",
            "Step    1\n",
            "  input: 44 ('ل')\n",
            "  expected output: 46 ('ن')\n",
            "Step    2\n",
            "  input: 46 ('ن')\n",
            "  expected output: 21 ('ا')\n",
            "Step    3\n",
            "  input: 21 ('ا')\n",
            "  expected output: 33 ('س')\n",
            "Step    4\n",
            "  input: 33 ('س')\n",
            "  expected output: 1 (' ')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "co90aS43K370",
        "outputId": "e60d0643-5f3a-494e-eda3-89e89d265a6e"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = examples_per_epoch//BATCH_SIZE\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liF897Y6K7-M"
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur4pt-YIK_m_"
      },
      "source": [
        "if tf.test.is_gpu_available():\n",
        "  rnn = tf.keras.layers.CuDNNGRU\n",
        "else:\n",
        "  import functools\n",
        "  rnn = functools.partial(\n",
        "    tf.keras.layers.GRU, recurrent_activation='sigmoid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "branxzjALChd"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    rnn(rnn_units,\n",
        "        return_sequences=True,\n",
        "        recurrent_initializer='glorot_uniform',\n",
        "        stateful=True),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR50bX1aLEd0"
      },
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFc8XTXNLXvR",
        "outputId": "ae60594f-b610-4151-b58f-b17d4b092f49"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 64) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LbGkbjuLaTf",
        "outputId": "f818e7a9-08a3-4fbb-e1bb-f92529ca8291"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           16384     \n",
            "_________________________________________________________________\n",
            "cu_dnngru (CuDNNGRU)         (64, None, 512)           1182720   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 64)            32832     \n",
            "=================================================================\n",
            "Total params: 1,231,936\n",
            "Trainable params: 1,231,936\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOZqLy08Leg1"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHep1BqwLjOQ",
        "outputId": "a685220f-a86d-444a-d62b-3dcf7e28eb1f"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([40, 57, 26, 45, 29, 40, 13, 31,  7, 20, 63, 50,  6, 36, 45, 25, 43,\n",
              "        5, 60, 13,  2,  0, 58,  9, 57, 53, 30, 48, 42, 15, 39, 24, 46, 42,\n",
              "       17, 57, 62, 49, 22,  0, 37, 14, 21,  9, 43, 40, 46, 50, 34, 20, 11,\n",
              "       50, 45, 27, 57, 28, 27, 36,  2, 16, 37, 60,  4, 44, 34, 36, 42,  3,\n",
              "       36, 56,  9, 21, 57, 32,  4, 13, 53, 38,  1, 47,  7,  7, 10,  3, 62,\n",
              "       18, 50, 18, 26, 61, 47, 46, 47, 33, 12, 38, 46, 14,  5, 38])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO_Eh4zQLloS",
        "outputId": "388a90f5-5945-44b8-ebc7-0a1ba8bd2e10"
      },
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            " 'ُمُّكَ النَفسُ قَديماً أَكرَمَت\\n\\nوَأَبوكَ الفَضلُ خَيرُ المُنجِبين\\n\\nنَسَبُ البَدرِ أَوِ الشَمسِ إِذا'\n",
            "\n",
            "Next Char Predictions: \n",
            " 'غّجمدغ؛ر4ئ…ي3ضمثك2پ؛!\\nْ6ٍّذوقءعتنقأّڤىب\\nط؟ا6كغنيشئ8يمحّخحض!آطپ1لشضق0ضِ6اّز1؛ٍظ ه4470ڤؤيؤجچهنهس9ظن؟2ظ'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eH6hvKLLpSh",
        "outputId": "382f923c-1021-43cd-ab7c-eef6190f68bc"
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 64)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       4.1591134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Giu51AJ6LtiF"
      },
      "source": [
        "model.compile(\n",
        "    optimizer = tf.train.AdamOptimizer(),\n",
        "    loss = loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L77sDc5MLwDq"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3YjuBGFdXEZ"
      },
      "source": [
        "db=dataset.repeat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwBzIc1Th241"
      },
      "source": [
        "! rm training_checkpoints/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf-t4XjxLzHu"
      },
      "source": [
        "EPOCHS=20\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilJW0k7XL0-u",
        "outputId": "3dc93807-b38f-4290-c485-c3f5a9515cce"
      },
      "source": [
        "history = model.fit(db, epochs=EPOCHS, steps_per_epoch=steps_per_epoch, callbacks=[checkpoint_callback])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "633/633 [==============================] - 30s 48ms/step - loss: 1.5880\n",
            "Epoch 2/20\n",
            "633/633 [==============================] - 29s 46ms/step - loss: 1.5883\n",
            "Epoch 3/20\n",
            "633/633 [==============================] - 28s 45ms/step - loss: 1.6036\n",
            "Epoch 4/20\n",
            "633/633 [==============================] - 29s 46ms/step - loss: 1.6003\n",
            "Epoch 5/20\n",
            "633/633 [==============================] - 29s 45ms/step - loss: 1.5967\n",
            "Epoch 6/20\n",
            "633/633 [==============================] - 29s 45ms/step - loss: 1.5978\n",
            "Epoch 7/20\n",
            "633/633 [==============================] - 28s 44ms/step - loss: 1.5961\n",
            "Epoch 8/20\n",
            "633/633 [==============================] - 28s 44ms/step - loss: 1.5950\n",
            "Epoch 9/20\n",
            "633/633 [==============================] - 28s 45ms/step - loss: 1.5934\n",
            "Epoch 10/20\n",
            "633/633 [==============================] - 28s 44ms/step - loss: 1.5925\n",
            "Epoch 11/20\n",
            "633/633 [==============================] - 28s 44ms/step - loss: 1.5935\n",
            "Epoch 12/20\n",
            "633/633 [==============================] - 28s 45ms/step - loss: 1.5921\n",
            "Epoch 13/20\n",
            "633/633 [==============================] - 28s 44ms/step - loss: 1.5907\n",
            "Epoch 14/20\n",
            "633/633 [==============================] - 28s 44ms/step - loss: 1.5913\n",
            "Epoch 15/20\n",
            "633/633 [==============================] - 28s 45ms/step - loss: 1.5886\n",
            "Epoch 16/20\n",
            "633/633 [==============================] - 28s 45ms/step - loss: 1.5908\n",
            "Epoch 17/20\n",
            "633/633 [==============================] - 28s 44ms/step - loss: 1.5891\n",
            "Epoch 18/20\n",
            "633/633 [==============================] - 28s 45ms/step - loss: 1.5888\n",
            "Epoch 19/20\n",
            "633/633 [==============================] - 28s 44ms/step - loss: 1.5885\n",
            "Epoch 20/20\n",
            "633/633 [==============================] - 28s 45ms/step - loss: 1.5879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmZY1QL8M6aN",
        "outputId": "c2746fd9-2090-4f6f-8618-42d8fc24edde"
      },
      "source": [
        "prefix=tf.train.latest_checkpoint(checkpoint_dir)\n",
        "print(prefix)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./training_checkpoints/ckpt_20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hc3J9QHkoMq6",
        "outputId": "968915cc-0705-44da-ffa2-17702daffa06"
      },
      "source": [
        "! tar -czvf trained.tgz ./training_checkpoints/checkpoint \"$prefix\"*"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./training_checkpoints/checkpoint\n",
            "./training_checkpoints/ckpt_20.data-00000-of-00002\n",
            "./training_checkpoints/ckpt_20.data-00001-of-00002\n",
            "./training_checkpoints/ckpt_20.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzPvKnwkM90C"
      },
      "source": [
        "model2 = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model2.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model2.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4cJqZcpNAg8",
        "outputId": "6b0b15f6-da9d-4464-de01-f376630bce94"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (1, None, 256)            16384     \n",
            "_________________________________________________________________\n",
            "cu_dnngru_6 (CuDNNGRU)       (1, None, 512)            1182720   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (1, None, 64)             32832     \n",
            "=================================================================\n",
            "Total params: 1,231,936\n",
            "Trainable params: 1,231,936\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMhus7gwL22E"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 1000\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  print(input_eval)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a multinomial distribution to predict the word returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.multinomial(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted word as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyjvq2taMZMl",
        "outputId": "1ef8b1ae-3509-42ba-fc60-e40bbec4b1a7"
      },
      "source": [
        "print(generate_text(model2, start_string=u\"سألتُ\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[33 17 44 24 55]], shape=(1, 5), dtype=int32)\n",
            "سألتُ هاويتي \n",
            "\n",
            "هل ثمَّيتُنَا \n",
            "\n",
            "كَم نَفَت صَفَحاتٍ لِلمُمَثِّليلَ بِضَرزامِكَ الغُرِّ أَرفى ال\n",
            "\n",
            "حُرَّةِ العُصفودَ وَإِن\n",
            "\n",
            "تَبكي بِها تِلكَ الكُؤوسُ بِهِ\n",
            "\n",
            "فَهيَ ذِمَرٌ عَلى أَمرِهِ\n",
            "\n",
            "حِمامُ الفيلِ مِن بُردَةٍ\n",
            "\n",
            "يَمضِ ما في كادِ طِفلالِ\n",
            "\n",
            "كُنتُ أَدعو رُواةُ المَنظَرُ\n",
            "\n",
            "فَيا لَيتَ شِعرِيَ وَالضُحى\n",
            "\n",
            "يَتيمَةً بَيتَنا بِالمَشيبِ\n",
            "\n",
            "خَليفَةَ الحَقِّ البُراقِ وَسُجّينا\n",
            "\n",
            "يَبكي الرِجالَ وَقَد تَنودَ بِقائِما\n",
            "\n",
            "وَالعُذرُ يا نَبَّلَت حَتَماما\n",
            "\n",
            "يا لَيتَ شَرَكاً وَالحالِدِ الوَقَر\n",
            "\n",
            "سَهِرَ الحَربُ حَولَ الجِكَلُ الحَياةُ\n",
            "\n",
            "وَتَضحى لِسانَها أَنّي في وَطَن\n",
            "\n",
            "أُم أَبَى لِستطاح الخَيرِ\n",
            "\n",
            "وَباتنا حَمؤولاً بِالكَذُب\n",
            "\n",
            "وَأَجَّ عَلى الزُهرِ موتَما اِتجادَ أَو\n",
            "\n",
            "كَفى بِشَرقِ رِداءِ ما خَفٍ\n",
            "\n",
            "فيهِ مِن تِركانِها وَخَذَلتُكَب\n",
            "\n",
            "اِذَّذَّهُ لِلذُدَر\n",
            "\n",
            "هُم أَوجَهُ العَهد وَالبِلادُ\n",
            "\n",
            "مَناحِها أَلقاكَ أَسعَدُها السَفينا\n",
            "\n",
            "فُجِئتَ بِها حَسوناً مَشى… موقظه من الكرمل\n",
            "\n",
            "هو منه تعطل فيه إذا يطفيهِ مسترجلاتُ\n",
            "\n",
            "من صَنَحْ ورسالة\n",
            "\n",
            "فسِر بعد أوسل وحشية نمرٍ؟\n",
            "\n",
            "إنَّ مناهنتي\n",
            "\n",
            "أنا المخلَّفُ ليست كل حُلْمِي \n",
            "\n",
            "واستربَلتْ ضافي\n",
            "\n",
            "دَولَةَ اللّه زِئن أمنٍ\n",
            "\n",
            "وأطلى \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEa_wjUSMcIR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}